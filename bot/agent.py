import json
import asyncio
import logging
from datetime import datetime
from typing import Optional, Dict, Any

import openai
import anthropic
from zep_cloud.client import AsyncZep
from zep_cloud.types import Message

from .config import (
    INSTRUCTION_FILE, OPENAI_API_KEY, OPENAI_MODEL, ZEP_API_KEY, ANTHROPIC_API_KEY, ANTHROPIC_MODEL,
    OPENAI_TEMPERATURE, OPENAI_MAX_TOKENS, OPENAI_PRESENCE_PENALTY, OPENAI_FREQUENCY_PENALTY, OPENAI_TOP_P,
    ANTHROPIC_TEMPERATURE, ANTHROPIC_MAX_TOKENS, GOOGLE_SHEETS_ENABLED, GOOGLE_SHEETS_SYNC_INTERVAL
)
from .memory import MemoryService, DialogState, ClientType
from .dialog_logger import dialog_logger

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
logger = logging.getLogger(__name__)


class AlenaAgent:
    """AI-Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ ÐÐ»Ñ‘Ð½Ð° Ñ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ð¾Ð¹ Ð¿Ð°Ð¼ÑÑ‚Ð¸"""
    
    def __init__(self):
        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ OpenAI ÐºÐ»Ð¸ÐµÐ½Ñ‚ ÐµÑÐ»Ð¸ API ÐºÐ»ÑŽÑ‡ Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½
        if OPENAI_API_KEY:
            self.openai_client = openai.AsyncOpenAI(api_key=OPENAI_API_KEY)
            print("âœ… OpenAI ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½")
        else:
            self.openai_client = None
            print("âš ï¸ OpenAI API ÐºÐ»ÑŽÑ‡ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½")
        
        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Anthropic ÐºÐ»Ð¸ÐµÐ½Ñ‚ ÐµÑÐ»Ð¸ API ÐºÐ»ÑŽÑ‡ Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½
        if ANTHROPIC_API_KEY:
            try:
                self.anthropic_client = anthropic.AsyncAnthropic(api_key=ANTHROPIC_API_KEY)
                print("âœ… Anthropic ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½")
            except Exception as e:
                print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Anthropic: {e}")
                self.anthropic_client = None
        else:
            self.anthropic_client = None
            print("âš ï¸ Anthropic API ÐºÐ»ÑŽÑ‡ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½")
            
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ‡Ñ‚Ð¾ Ñ…Ð¾Ñ‚Ñ Ð±Ñ‹ Ð¾Ð´Ð¸Ð½ LLM Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½
        if not self.openai_client and not self.anthropic_client:
            print("âš ï¸ ÐÐ¸ Ð¾Ð´Ð¸Ð½ LLM Ð½Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ ÑƒÐ¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼")
        
        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½ÑƒÑŽ ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ Ð¿Ð°Ð¼ÑÑ‚Ð¸
        enable_memory = bool(ZEP_API_KEY and ZEP_API_KEY != "test_key")
        self.memory_service = MemoryService(ZEP_API_KEY or "", enable_memory=enable_memory)
        
        if enable_memory:
            print(f"âœ… Ð˜Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð¿Ð°Ð¼ÑÑ‚Ð¸ Ð°ÐºÑ‚Ð¸Ð²Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð°")
            print(f"ðŸ§  ZEP API Key: {ZEP_API_KEY[:8]}...{ZEP_API_KEY[-4:]}")
        else:
            print("âš ï¸ Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¿Ð°Ð¼ÑÑ‚Ð¸ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ð² Ð±Ð°Ð·Ð¾Ð²Ð¾Ð¼ Ñ€ÐµÐ¶Ð¸Ð¼Ðµ (Ð±ÐµÐ· ZEP)")
        
        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Zep ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ð´Ð»Ñ ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚Ð¸
        self.zep_client = self.memory_service.zep_client
        
        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Google Sheets Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸ÑŽ
        self.sheets_service = None
        if GOOGLE_SHEETS_ENABLED and enable_memory:
            try:
                from .integrations.google_sheets_service import GoogleSheetsService
                self.sheets_service = GoogleSheetsService(
                    self.memory_service, 
                    self.memory_service.analytics_service
                )
                print("âœ… Google Sheets Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð°")
            except Exception as e:
                print(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Google Sheets: {e}")
                self.sheets_service = None
        elif GOOGLE_SHEETS_ENABLED:
            print("âš ï¸ Google Sheets Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð¿Ð°Ð¼ÑÑ‚Ð¸ ZEP")
        
        self.instruction = self._load_instruction()
    
    def _load_instruction(self) -> Dict[str, Any]:
        try:
            with open(INSTRUCTION_FILE, 'r', encoding='utf-8') as f:
                instruction = json.load(f)
                logger.info(f"âœ… Ð˜Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹ Ð¸Ð· {INSTRUCTION_FILE}")
                logger.info(f"ðŸ“ ÐŸÐ¾ÑÐ»ÐµÐ´Ð½ÐµÐµ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ: {instruction.get('last_updated', 'Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾')}")
                logger.info(f"ðŸ“ Ð”Ð»Ð¸Ð½Ð° ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ð¹ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸: {len(instruction.get('system_instruction', ''))}")
                print(f"âœ… Ð˜Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹ Ð¸Ð· {INSTRUCTION_FILE}")
                print(f"ðŸ“ ÐŸÐ¾ÑÐ»ÐµÐ´Ð½ÐµÐµ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ: {instruction.get('last_updated', 'Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾')}")
                return instruction
        except FileNotFoundError:
            logger.warning(f"âš ï¸ Ð’ÐÐ˜ÐœÐÐÐ˜Ð•: Ð¤Ð°Ð¹Ð» {INSTRUCTION_FILE} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½! Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð±Ð°Ð·Ð¾Ð²Ð°Ñ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ñ.")
            print(f"âš ï¸ Ð’ÐÐ˜ÐœÐÐÐ˜Ð•: Ð¤Ð°Ð¹Ð» {INSTRUCTION_FILE} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½! Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð±Ð°Ð·Ð¾Ð²Ð°Ñ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ñ.")
            return {
                "system_instruction": "Ð’Ñ‹ - Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº ÑÐ»ÑƒÐ¶Ð±Ñ‹ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸ Textil PRO.",
                "welcome_message": "Ð”Ð¾Ð±Ñ€Ð¾ Ð¿Ð¾Ð¶Ð°Ð»Ð¾Ð²Ð°Ñ‚ÑŒ! Ð§ÐµÐ¼ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ?",
                "last_updated": datetime.now().isoformat()
            }
        except Exception as e:
            print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¹: {e}")
            return {
                "system_instruction": "Ð’Ñ‹ - Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº ÑÐ»ÑƒÐ¶Ð±Ñ‹ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸ Textil PRO.",
                "welcome_message": "Ð”Ð¾Ð±Ñ€Ð¾ Ð¿Ð¾Ð¶Ð°Ð»Ð¾Ð²Ð°Ñ‚ÑŒ! Ð§ÐµÐ¼ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ?",
                "last_updated": datetime.now().isoformat()
            }
    
    def reload_instruction(self):
        logger.info("ðŸ”„ ÐŸÐµÑ€ÐµÐ·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¹...")
        print("ðŸ”„ ÐŸÐµÑ€ÐµÐ·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¹...")
        old_updated = self.instruction.get('last_updated', 'Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾')
        self.instruction = self._load_instruction()
        new_updated = self.instruction.get('last_updated', 'Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾')
        
        if old_updated != new_updated:
            logger.info(f"âœ… Ð˜Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ñ‹: {old_updated} -> {new_updated}")
            print(f"âœ… Ð˜Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ñ‹: {old_updated} -> {new_updated}")
        else:
            logger.info("ðŸ“ Ð˜Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸ Ð¿ÐµÑ€ÐµÐ·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹ (Ð±ÐµÐ· Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹)")
            print("ðŸ“ Ð˜Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸ Ð¿ÐµÑ€ÐµÐ·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹ (Ð±ÐµÐ· Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹)")
    
    
    async def call_llm(self, messages: list, max_tokens: int = None, temperature: float = None) -> str:
        """Ð Ð¾ÑƒÑ‚ÐµÑ€ LLM Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ñ fallback Ð¼ÐµÐ¶Ð´Ñƒ OpenAI Ð¸ Anthropic (Ñ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼Ð¸ Ð´Ð»Ñ Ð¶Ð¸Ð²Ð¾Ð³Ð¾ Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ)"""
        
        # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ ÐµÑÐ»Ð¸ Ð½Ðµ Ð¿ÐµÑ€ÐµÐ´Ð°Ð½Ñ‹
        max_tokens = max_tokens or OPENAI_MAX_TOKENS
        temperature = temperature or OPENAI_TEMPERATURE
        
        # Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ OpenAI
        if self.openai_client:
            try:
                logger.info(f"ðŸ¤– OpenAI Ð·Ð°Ð¿Ñ€Ð¾Ñ: temp={temperature}, tokens={max_tokens}, presence={OPENAI_PRESENCE_PENALTY}, frequency={OPENAI_FREQUENCY_PENALTY}")
                response = await self.openai_client.chat.completions.create(
                    model=OPENAI_MODEL,
                    messages=messages,
                    max_tokens=max_tokens,
                    temperature=temperature,
                    presence_penalty=OPENAI_PRESENCE_PENALTY,
                    frequency_penalty=OPENAI_FREQUENCY_PENALTY,
                    top_p=OPENAI_TOP_P
                )
                result = response.choices[0].message.content
                logger.info("âœ… OpenAI Ð¾Ñ‚Ð²ÐµÑ‚ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½ Ñ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ñ‹Ð¼Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼Ð¸")
                return result
                
            except Exception as e:
                logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° OpenAI: {e}")
                print(f"âŒ OpenAI Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½: {e}")
        
        # Fallback Ð½Ð° Anthropic
        if self.anthropic_client:
            try:
                # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Anthropic ÐµÑÐ»Ð¸ OpenAI Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½
                anthropic_max_tokens = max_tokens or ANTHROPIC_MAX_TOKENS
                anthropic_temperature = temperature or ANTHROPIC_TEMPERATURE
                
                logger.info(f"ðŸ¤– Fallback Ð½Ð° Anthropic: temp={anthropic_temperature}, tokens={anthropic_max_tokens}")
                
                # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Anthropic API
                system_message = ""
                user_messages = []
                
                for msg in messages:
                    if msg["role"] == "system":
                        system_message = msg["content"]
                    else:
                        user_messages.append(msg)
                
                response = await self.anthropic_client.messages.create(
                    model=ANTHROPIC_MODEL,
                    max_tokens=anthropic_max_tokens,
                    temperature=anthropic_temperature,
                    system=system_message,
                    messages=user_messages
                )
                
                result = response.content[0].text
                logger.info("âœ… Anthropic Ð¾Ñ‚Ð²ÐµÑ‚ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½")
                return result
                
            except Exception as e:
                logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Anthropic: {e}")
                print(f"âŒ Anthropic Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½: {e}")
        
        # Ð•ÑÐ»Ð¸ Ð¾Ð±Ð° LLM Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹ - Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ fallback Ð»Ð¾Ð³Ð¸ÐºÑƒ
        logger.warning("âŒ Ð’ÑÐµ LLM Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½ÑƒÑŽ Ð»Ð¾Ð³Ð¸ÐºÑƒ")
        return self._fallback_response(messages[-1]["content"] if messages else "")
    
    def _fallback_response(self, user_message: str) -> str:
        """Fallback Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ ÐºÐ¾Ð³Ð´Ð° LLM Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹ - Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚"""
        logger.warning("âš ï¸ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ fallback Ð¾Ñ‚Ð²ÐµÑ‚ - LLM Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹")
        return "Ð—Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹Ñ‚Ðµ! Ð¯ ÐÐ»ÐµÐ½Ð°, Ð²Ð°Ñˆ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð¿Ð¾ Ð½ÐµÐ´Ð²Ð¸Ð¶Ð¸Ð¼Ð¾ÑÑ‚Ð¸ Ð² Ð¡Ð¾Ñ‡Ð¸. Ð§ÐµÐ¼ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ?"
    
    async def generate_response(self, user_message: str, session_id: str, user_name: str = None,
                               chat_id: str = None, existing_session_id: str = None) -> str:
        try:
            # ðŸ§  Ð˜ÐÐ¢Ð•Ð›Ð›Ð•ÐšÐ¢Ð£ÐÐ›Ð¬ÐÐÐ¯ ÐžÐ‘Ð ÐÐ‘ÐžÐ¢ÐšÐ Ð¡ÐžÐžÐ‘Ð©Ð•ÐÐ˜Ð¯
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð½Ð¾Ð²ÑƒÑŽ ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ ÑÐµÑÑÐ¸Ð¹ Ñ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ session_id
            try:
                memory_result = await self.memory_service.process_message(
                    user_id=session_id,
                    message_text=user_message,
                    chat_id=chat_id,
                    existing_session_id=existing_session_id
                )
            except Exception as memory_error:
                logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð¿Ð°Ð¼ÑÑ‚Ð¸ (ZEP Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½): {memory_error}")
                # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹
                memory_result = {'success': False, 'error': str(memory_error)}

            if not memory_result.get('success', False):
                logger.warning(f"âš ï¸ Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¿Ð°Ð¼ÑÑ‚Ð¸ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°: {memory_result.get('error')}")
                # ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ Ñ Ð±Ð°Ð·Ð¾Ð²Ð¾Ð¹ Ð»Ð¾Ð³Ð¸ÐºÐ¾Ð¹ Ð±ÐµÐ· ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð¿Ð°Ð¼ÑÑ‚Ð¸
            
            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ðµ Ð¸ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ð¸ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°
            lead_data = memory_result.get('lead_data')
            current_state = memory_result.get('current_state', DialogState.S0_GREETING)
            qualification_status = memory_result.get('qualification_status', ClientType.COLD)
            recommendations = memory_result.get('recommendations', {})
            should_escalate = memory_result.get('should_escalate', False)

            # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ð²Ñ…Ð¾Ð´ÑÑ‰ÐµÐµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ
            dialog_logger.log_message(
                session_id=session_id,
                user_id=session_id.split('_')[0] if '_' in session_id else session_id,
                user_name=user_name or "Unknown",
                message_type="user",
                text=user_message,
                state=current_state.value if hasattr(current_state, 'value') else str(current_state),
                qualification=qualification_status.value if hasattr(qualification_status, 'value') else str(qualification_status)
            )
            
            # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼
            system_prompt = self._build_contextual_system_prompt(
                lead_data, current_state, qualification_status, recommendations
            )
            
            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°
            dialog_history = await self.memory_service.get_dialog_history(session_id, limit=5)
            
            # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð´Ð»Ñ LLM
            messages = self._build_llm_messages(
                system_prompt, user_message, dialog_history, recommendations
            )
            
            # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚ Ñ‡ÐµÑ€ÐµÐ· LLM
            if self.openai_client or self.anthropic_client:
                try:
                    bot_response = await self.call_llm(messages)
                except Exception as llm_error:
                    logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° LLM Ñ€Ð¾ÑƒÑ‚ÐµÑ€Ð°: {llm_error}")
                    bot_response = self._fallback_response_with_context(
                        user_message, current_state, recommendations
                    )
            else:
                bot_response = self._fallback_response_with_context(
                    user_message, current_state, recommendations
                )
            
            # ðŸš¨ ÐŸÐ ÐžÐ’Ð•Ð ÐšÐ ÐÐ Ð­Ð¡ÐšÐÐ›ÐÐ¦Ð˜Ð®
            if should_escalate:
                escalation_note = self._generate_escalation_summary(lead_data)
                logger.info(f"ðŸ”¥ Ð­Ð¡ÐšÐÐ›ÐÐ¦Ð˜Ð¯ Ð´Ð»Ñ {session_id}: {escalation_note}")
                print(f"ðŸ”¥ Ð“ÐžÐ Ð¯Ð§Ð˜Ð™ Ð›Ð˜Ð”: {session_id} - {escalation_note}")

            # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚ Ð±Ð¾Ñ‚Ð°
            dialog_logger.log_message(
                session_id=session_id,
                user_id=session_id.split('_')[0] if '_' in session_id else session_id,
                user_name=user_name or "Unknown",
                message_type="assistant",
                text=bot_response,
                state=current_state.value,
                qualification=qualification_status.value,
                metadata={
                    "should_escalate": should_escalate,
                    "recommendations": recommendations,
                    "chat_id": chat_id
                }
            )

            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚ Ð² Ð¿Ð°Ð¼ÑÑ‚ÑŒ
            await self.memory_service.process_message(
                user_id=session_id,
                message_text=bot_response,
                message_type="assistant",
                chat_id=chat_id,
                existing_session_id=existing_session_id
            )
            
            # Ð¡Ð¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ Google Sheets Ð¿Ñ€Ð¸ Ð·Ð½Ð°Ñ‡Ð¸Ð¼Ñ‹Ñ… Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸ÑÑ…
            if self.sheets_service and lead_data:
                try:
                    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÐµÑÑ‚ÑŒ Ð»Ð¸ Ð·Ð½Ð°Ñ‡Ð¸Ð¼Ñ‹Ðµ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ Ð² Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð»Ð¸Ð´Ð°
                    significant_changes = (
                        should_escalate or 
                        qualification_status in [ClientType.WARM, ClientType.HOT] or
                        current_state in [DialogState.S3_PAYMENT, DialogState.S5_BUDGET, DialogState.S8_ACTION]
                    )
                    
                    if significant_changes:
                        # ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ð°Ñ ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð±ÐµÐ· Ð±Ð»Ð¾ÐºÐ¸Ñ€Ð¾Ð²ÐºÐ¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
                        asyncio.create_task(self._sync_to_sheets_async(session_id))
                        logger.debug(f"ðŸ“Š Ð—Ð°Ð¿ÑƒÑ‰ÐµÐ½Ð° ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ Google Sheets Ð´Ð»Ñ {session_id}")
                        
                except Exception as sheets_error:
                    logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Google Sheets: {sheets_error}")
            
            return bot_response
            
        except Exception as e:
            logger.error(f"âŒ ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð´Ð»Ñ {session_id}: {e}")
            return self._emergency_fallback_response(user_message)
    
    def _build_contextual_system_prompt(self, lead_data, current_state: DialogState, 
                                      qualification_status: ClientType, 
                                      recommendations: Dict[str, Any]) -> str:
        """Ð¡Ñ‚Ñ€Ð¾Ð¸Ñ‚ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚"""
        base_prompt = self.instruction.get("system_instruction", "")
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¾ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ðµ
        context_parts = []
        
        if lead_data:
            client_info = []
            
            # Ð‘Ð°Ð·Ð¾Ð²Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ
            if lead_data.name:
                client_info.append(f"Ð˜Ð¼Ñ: {lead_data.name}")
            if getattr(lead_data, 'city', None):
                client_info.append(f"Ð“Ð¾Ñ€Ð¾Ð´: {lead_data.city}")
            if getattr(lead_data, 'is_in_sochi', None) is not None:
                sochi_status = "Ð² Ð¡Ð¾Ñ‡Ð¸" if lead_data.is_in_sochi else "Ð½Ðµ Ð² Ð¡Ð¾Ñ‡Ð¸"
                client_info.append(f"Ð¡Ñ‚Ð°Ñ‚ÑƒÑ: {sochi_status}")
                
            # Ð¦ÐµÐ»ÑŒ Ð¸ Ð±ÑŽÐ´Ð¶ÐµÑ‚
            if lead_data.automation_goal:
                client_info.append(f"Ð¦ÐµÐ»ÑŒ: {lead_data.automation_goal.value}")
            if lead_data.budget_min or lead_data.budget_max:
                budget = f"Ð‘ÑŽÐ´Ð¶ÐµÑ‚: {lead_data.budget_min or 0}-{lead_data.budget_max or 'âˆž'} Ñ€ÑƒÐ±"
                client_info.append(budget)
            if lead_data.payment_type:
                client_info.append(f"ÐžÐ¿Ð»Ð°Ñ‚Ð°: {lead_data.payment_type.value}")
                
            # ÐŸÑ€ÐµÐ´Ð¿Ð¾Ñ‡Ñ‚ÐµÐ½Ð¸Ñ Ð¿Ð¾ Ð½ÐµÐ´Ð²Ð¸Ð¶Ð¸Ð¼Ð¾ÑÑ‚Ð¸
            if getattr(lead_data, 'preferred_locations', None):
                locations = ", ".join(lead_data.preferred_locations)
                client_info.append(f"Ð›Ð¾ÐºÐ°Ñ†Ð¸Ð¸: {locations}")
            if getattr(lead_data, 'property_type', None):
                client_info.append(f"Ð¢Ð¸Ð¿: {lead_data.property_type}")
                
            # Ð¡Ñ€Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ
            if getattr(lead_data, 'urgency_date', None):
                client_info.append(f"ÐŸÑ€Ð¸ÐµÐ·Ð´: {lead_data.urgency_date}")
            
            if client_info:
                context_parts.append(f"Ð”ÐÐÐÐ«Ð• ÐšÐ›Ð˜Ð•ÐÐ¢Ð: {' | '.join(client_info)}")
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° (Ð½ÐµÐ´Ð²Ð¸Ð¶Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¡Ð¾Ñ‡Ð¸)
        state_descriptions = {
            DialogState.S0_GREETING: "ÐŸÐµÑ€Ð²Ð¾Ðµ Ð·Ð½Ð°ÐºÐ¾Ð¼ÑÑ‚Ð²Ð¾ - Ð²Ñ‹ÑÑÐ½Ð¸Ñ‚Ðµ Ñ†ÐµÐ»ÑŒ Ð¿Ð¾ÐºÑƒÐ¿ÐºÐ¸",
            DialogState.S1_BUSINESS: "Ð£Ð·Ð½Ð°Ð¹Ñ‚Ðµ Ð¼ÐµÑÑ‚Ð¾Ð¿Ð¾Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° Ð¸ Ð³Ð¾Ñ€Ð¾Ð´", 
            DialogState.S2_GOAL: "ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚Ðµ Ñ†ÐµÐ»ÑŒ Ð¿Ð¾ÐºÑƒÐ¿ÐºÐ¸ Ð½ÐµÐ´Ð²Ð¸Ð¶Ð¸Ð¼Ð¾ÑÑ‚Ð¸",
            DialogState.S3_PAYMENT: "ÐžÐ±ÑÑƒÐ´Ð¸Ñ‚Ðµ Ñ„Ð¾Ñ€Ð¼Ñƒ Ð¾Ð¿Ð»Ð°Ñ‚Ñ‹ Ð¸ Ð±ÑŽÐ´Ð¶ÐµÑ‚",
            DialogState.S4_REQUIREMENTS: "Ð’Ñ‹ÑÑÐ½Ð¸Ñ‚Ðµ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°ÑŽÑ‰Ð¸Ðµ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ Ðº Ð¾Ð±ÑŠÐµÐºÑ‚Ñƒ (Ñ‚Ð¸Ð¿, Ð»Ð¾ÐºÐ°Ñ†Ð¸Ñ, Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹)",
            DialogState.S5_BUDGET: "Ð£Ñ‚Ð¾Ñ‡Ð½Ð¸Ñ‚Ðµ Ð±ÑŽÐ´Ð¶ÐµÑ‚ Ñ‡ÐµÑ€ÐµÐ· Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñ‹",
            DialogState.S6_URGENCY: "ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚Ðµ ÑÑ€Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾ÐºÑƒÐ¿ÐºÐ¸",
            DialogState.S7_EXPERIENCE: "Ð£Ð·Ð½Ð°Ð¹Ñ‚Ðµ Ð¾Ð¿Ñ‹Ñ‚ Ð¿Ð¾ÐºÑƒÐ¿ÐºÐ¸ Ð² Ð¡Ð¾Ñ‡Ð¸",
            DialogState.S8_ACTION: "ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶Ð¸Ñ‚Ðµ Ð¾Ð½Ð»Ð°Ð¹Ð½-Ð¿Ð¾ÐºÐ°Ð· Ð¸Ð»Ð¸ Ð²ÑÑ‚Ñ€ÐµÑ‡Ñƒ"
        }
        
        state_desc = state_descriptions.get(current_state, "")
        context_parts.append(f"Ð­Ð¢ÐÐŸ Ð”Ð˜ÐÐ›ÐžÐ“Ð: {current_state.value} - {state_desc}")
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚ÑƒÑ ÐºÐ²Ð°Ð»Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸
        status_descriptions = {
            ClientType.COLD: "Ð¥ÐžÐ›ÐžÐ”ÐÐ«Ð™ - Ð½ÑƒÐ¶Ð½Ð° Ð±Ð°Ð·Ð¾Ð²Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð½Ð¾ÑÑ‚ÑÑ…",
            ClientType.WARM: "Ð¢ÐÐŸÐ›Ð«Ð™ - ÐµÑÑ‚ÑŒ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑ, Ñ€Ð°Ð·Ð²Ð¸Ð²Ð°Ð¹Ñ‚Ðµ Ð´Ð¸Ð°Ð»Ð¾Ð³", 
            ClientType.HOT: "Ð“ÐžÐ Ð¯Ð§Ð˜Ð™ - Ð³Ð¾Ñ‚Ð¾Ð² Ðº Ð¿Ð¾ÐºÑƒÐ¿ÐºÐµ, Ð¿Ñ€ÐµÐ´Ð»Ð°Ð³Ð°Ð¹Ñ‚Ðµ Ð¾Ð½Ð»Ð°Ð¹Ð½-Ð¿Ð¾ÐºÐ°Ð·!"
        }
        
        status_desc = status_descriptions.get(qualification_status, "")
        context_parts.append(f"Ð¡Ð¢ÐÐ¢Ð£Ð¡ ÐšÐ›Ð˜Ð•ÐÐ¢Ð: {status_desc}")
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸
        if recommendations.get('next_questions'):
            questions = recommendations['next_questions'][:2]  # ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ 2 Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°
            context_parts.append(f"Ð Ð•ÐšÐžÐœÐ•ÐÐ”Ð£Ð•ÐœÐ«Ð• Ð’ÐžÐŸÐ ÐžÐ¡Ð«: {' | '.join(questions)}")
        
        if recommendations.get('demo_ready'):
            context_parts.append("ðŸŽ¯ Ð“ÐžÐ¢ÐžÐ’ Ðš ÐŸÐžÐšÐÐ—Ð£: ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶Ð¸Ñ‚Ðµ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ ÑÐ»Ð¾Ñ‚Ñ‹ Ð´Ð»Ñ Ð¾Ð½Ð»Ð°Ð¹Ð½-Ð¿Ð¾ÐºÐ°Ð·Ð°!")
        
        # ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼ Ð²ÑÐµ Ñ‡Ð°ÑÑ‚Ð¸
        if context_parts:
            base_prompt += f"\n\n{'='*50}\n" + "\n".join(context_parts) + f"\n{'='*50}"
        
        return base_prompt
    
    def _build_llm_messages(self, system_prompt: str, user_message: str, 
                           dialog_history: list, recommendations: Dict[str, Any]) -> list:
        """Ð¡Ñ‚Ñ€Ð¾Ð¸Ñ‚ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð´Ð»Ñ LLM Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸"""
        messages = [{"role": "system", "content": system_prompt}]
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÑ€Ð°Ñ‚ÐºÑƒÑŽ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ
        if dialog_history:
            history_text = "ÐÐ•Ð”ÐÐ’ÐÐ˜Ð• Ð¡ÐžÐžÐ‘Ð©Ð•ÐÐ˜Ð¯:\n"
            for msg in dialog_history[-3:]:  # ÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 3 ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ
                role = "ðŸ‘¤ ÐšÐ»Ð¸ÐµÐ½Ñ‚" if msg['role'] == 'user' else "ðŸ¤– ÐÐ»Ñ‘Ð½Ð°"
                content = msg['content'][:200] if len(msg['content']) > 200 else msg['content']
                history_text += f"{role}: {content}\n"
            
            messages.append({"role": "system", "content": history_text})
        
        # Ð¢ÐµÐºÑƒÑ‰ÐµÐµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
        messages.append({"role": "user", "content": user_message})
        
        return messages
    
    def _fallback_response_with_context(self, user_message: str, current_state: DialogState,
                                      recommendations: Dict[str, Any]) -> str:
        """Fallback Ð¾Ñ‚Ð²ÐµÑ‚ Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°"""
        logger.warning("âš ï¸ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ fallback Ð¾Ñ‚Ð²ÐµÑ‚ Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼ - LLM Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹")

        # Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°
        if current_state == DialogState.S0_GREETING:
            return "Ð—Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹Ñ‚Ðµ! Ð¯ ÐÐ»ÐµÐ½Ð°, Ð²Ð°Ñˆ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð¿Ð¾ Ð½ÐµÐ´Ð²Ð¸Ð¶Ð¸Ð¼Ð¾ÑÑ‚Ð¸ Ð² Ð¡Ð¾Ñ‡Ð¸. ÐŸÐ¾Ð´ÑÐºÐ°Ð¶Ð¸Ñ‚Ðµ, Ð¸Ñ‰ÐµÑ‚Ðµ Ð´Ð»Ñ ÑÐµÐ±Ñ Ð¸Ð»Ð¸ ÐºÐ°Ðº Ð¸Ð½Ð²ÐµÑÑ‚Ð¸Ñ†Ð¸ÑŽ?"
        elif current_state == DialogState.S1_GOAL_PURPOSE:
            return "ÐŸÐ¾Ð½ÑÐ»Ð° Ð²Ð°Ñ. Ð’Ñ‹ ÑÐµÐ¹Ñ‡Ð°Ñ Ð² Ð¡Ð¾Ñ‡Ð¸? Ð˜Ð»Ð¸ Ð¿Ð»Ð°Ð½Ð¸Ñ€ÑƒÐµÑ‚Ðµ Ð¿Ñ€Ð¸ÐµÐ·Ð´? Ð•ÑÐ»Ð¸ Ð½ÐµÑ‚ - Ð¸Ð· ÐºÐ°ÐºÐ¾Ð³Ð¾ Ð³Ð¾Ñ€Ð¾Ð´Ð° Ð±ÑƒÐ´ÐµÑ‚Ðµ Ñ€Ð°ÑÑÐ¼Ð°Ñ‚Ñ€Ð¸Ð²Ð°Ñ‚ÑŒ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ñ‹?"
        elif recommendations and 'questions' in recommendations:
            questions = recommendations['questions']
            if questions:
                return questions[0]

        # Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ
        return "Ð¡Ð¿Ð°ÑÐ¸Ð±Ð¾ Ð·Ð° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ! Ð£Ñ‚Ð¾Ñ‡Ð½Ð¸Ñ‚Ðµ, Ð¿Ð¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð´Ð»Ñ ÑÐµÐ±Ñ Ð¸Ñ‰ÐµÑ‚Ðµ Ð½ÐµÐ´Ð²Ð¸Ð¶Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¸Ð»Ð¸ ÐºÐ°Ðº Ð¸Ð½Ð²ÐµÑÑ‚Ð¸Ñ†Ð¸ÑŽ?"
    
    def _emergency_fallback_response(self, user_message: str) -> str:
        """ÐÐ²Ð°Ñ€Ð¸Ð¹Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¿Ñ€Ð¸ Ð¿Ð¾Ð»Ð½Ð¾Ð¼ Ð¾Ñ‚ÐºÐ°Ð·Ðµ ÑÐ¸ÑÑ‚ÐµÐ¼"""
        logger.error("ðŸ†˜ ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°: Ð²ÑÐµ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð°Ð²Ð°Ñ€Ð¸Ð¹Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚")
        return "Ð—Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹Ñ‚Ðµ! Ð¯ ÐÐ»ÐµÐ½Ð°, Ð²Ð°Ñˆ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð¿Ð¾ Ð½ÐµÐ´Ð²Ð¸Ð¶Ð¸Ð¼Ð¾ÑÑ‚Ð¸ Ð² Ð¡Ð¾Ñ‡Ð¸. ÐŸÐ¾Ð´ÑÐºÐ°Ð¶Ð¸Ñ‚Ðµ, Ð¿Ð¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð´Ð»Ñ ÑÐµÐ±Ñ Ð¸Ñ‰ÐµÑ‚Ðµ Ð¸Ð»Ð¸ ÐºÐ°Ðº Ð¸Ð½Ð²ÐµÑÑ‚Ð¸Ñ†Ð¸ÑŽ?"
    
    def _generate_escalation_summary(self, lead_data) -> str:
        """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ ÑÐ²Ð¾Ð´ÐºÑƒ Ð´Ð»Ñ ÑÑÐºÐ°Ð»Ð°Ñ†Ð¸Ð¸"""
        if not lead_data:
            return "Ð“Ð¾Ñ€ÑÑ‡Ð¸Ð¹ Ð»Ð¸Ð´ Ð±ÐµÐ· Ð´Ð°Ð½Ð½Ñ‹Ñ…"
        
        summary_parts = []
        
        if lead_data.name:
            summary_parts.append(f"Ð˜Ð¼Ñ: {lead_data.name}")
        if lead_data.phone:
            summary_parts.append(f"Ð¢ÐµÐ»ÐµÑ„Ð¾Ð½: {lead_data.phone}")
        if lead_data.business_sphere:
            summary_parts.append(f"Ð¡Ñ„ÐµÑ€Ð°: {lead_data.business_sphere}")
        if lead_data.budget_max:
            summary_parts.append(f"Ð‘ÑŽÐ´Ð¶ÐµÑ‚: Ð´Ð¾ ${lead_data.budget_max}")
        if lead_data.automation_goal:
            summary_parts.append(f"Ð¦ÐµÐ»ÑŒ: {lead_data.automation_goal.value}")
        
        return " | ".join(summary_parts) if summary_parts else "Ð“Ð¾Ñ€ÑÑ‡Ð¸Ð¹ Ð»Ð¸Ð´ - Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ"
    
    # ÐÐ¾Ð²Ñ‹Ðµ Ð¼ÐµÑ‚Ð¾Ð´Ñ‹ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð¾Ð¹ Ð¿Ð°Ð¼ÑÑ‚Ð¸
    async def get_lead_analytics(self, session_id: str) -> Dict[str, Any]:
        """ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÑƒ Ð¿Ð¾ Ð»Ð¸Ð´Ñƒ"""
        return await self.memory_service.get_analytics_summary(session_id)
    
    async def get_memory_insights(self, session_id: str) -> Dict[str, Any]:
        """ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ñ‹ Ð¸Ð· ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð¿Ð°Ð¼ÑÑ‚Ð¸"""
        try:
            lead_data = await self.memory_service.get_lead_data(session_id)
            dialog_history = await self.memory_service.get_dialog_history(session_id, limit=20)
            
            return {
                'lead_data': lead_data.to_dict() if lead_data else {},
                'dialog_history': dialog_history,
                'current_state': lead_data.current_dialog_state.value if lead_data else 's0_greeting',
                'qualification_status': lead_data.qualification_status.value if lead_data and lead_data.qualification_status else 'cold',
                'should_escalate': self.memory_service._should_escalate(lead_data) if lead_data else False
            }
        except Exception as e:
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ð¾Ð² Ð¿Ð°Ð¼ÑÑ‚Ð¸ Ð´Ð»Ñ {session_id}: {e}")
            return {}
    
    async def process_reminder_due(self, session_id: str) -> Optional[str]:
        """ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ðµ Ð½Ð°Ð¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ñ"""
        try:
            due_reminders = await self.memory_service.reminders.get_due_reminders()
            session_reminders = [r for r in due_reminders if r.session_id == session_id]
            
            if session_reminders:
                reminder = session_reminders[0]  # Ð‘ÐµÑ€ÐµÐ¼ Ð¿ÐµÑ€Ð²Ð¾Ðµ
                lead_data = await self.memory_service.get_lead_data(session_id)
                
                # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð½Ð°Ð¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ñ
                message = await self.memory_service.reminders.generate_reminder_message(
                    reminder, lead_data.to_dict() if lead_data else None
                )
                
                # ÐŸÐ¾Ð¼ÐµÑ‡Ð°ÐµÐ¼ ÐºÐ°Ðº Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð½Ð¾Ðµ
                await self.memory_service.reminders.mark_reminder_completed(reminder)
                
                return message
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð½Ð°Ð¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ñ Ð´Ð»Ñ {session_id}: {e}")
            return None
    
    
    async def _sync_to_sheets_async(self, session_id: str):
        """ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ð°Ñ ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ñ Google Sheets"""
        if not self.sheets_service:
            return

        try:
            await self.sheets_service.sync_leads_data(days=30)
            await self.sheets_service.sync_analytics_data(days=30)
        except Exception as e:
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Google Sheets: {e}")
    
    async def get_sheets_url(self) -> Optional[str]:
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ URL Google Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ ÐµÑÐ»Ð¸ Ð¾Ð½Ð° ÑÐ¾Ð·Ð´Ð°Ð½Ð°"""
        if self.sheets_service:
            return await self.sheets_service.get_spreadsheet_url()
        return None
    
    async def manual_sheets_sync(self) -> bool:
        """Ð ÑƒÑ‡Ð½Ð°Ñ ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ñ Google Sheets"""
        if not self.sheets_service:
            return False

        try:
            leads_success = await self.sheets_service.sync_leads_data(days=30)
            analytics_success = await self.sheets_service.sync_analytics_data(days=30)
            return leads_success and analytics_success
        except Exception as e:
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Google Sheets: {e}")
            return False

    def get_welcome_message(self) -> str:
        return self.instruction.get("welcome_message", "Ð”Ð¾Ð±Ñ€Ð¾ Ð¿Ð¾Ð¶Ð°Ð»Ð¾Ð²Ð°Ñ‚ÑŒ!")


agent = AlenaAgent()